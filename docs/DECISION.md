# Local Brain: Architecture Decision Record

**Date:** December 8, 2025  
**Status:** Approved  
**Context:** Claude Code skill delegation to local Ollama models

---

## Executive Summary

After multi-model research analysis, the decision is to **keep the current implementation** with incremental improvements, while evaluating Smolagents as a future option.

---

## The Actual Use Case

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     delegates      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     calls      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Claude Code â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Local Brain â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Ollama  â”‚
â”‚   (Cloud)   â”‚                    â”‚   (Local)   â”‚                â”‚ (Local) â”‚
â”‚             â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚             â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     returns        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    responds    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    results                           with tools
```

**Key Insight:** Local Brain is NOT a standalone CLI competing with Aider. It's a **delegation target** for Claude Code skills, providing local model access with codebase tools.

---

## Decision: Keep Current Implementation

### Why NOT Aider
- Aider is **interactive** (designed for humans in terminals)
- No programmatic API for delegation
- Expects user input/confirmation loops
- Cannot be called as a subprocess with structured results

### Why NOT Frameworks (LangChain, LlamaIndex, etc.)
- **Overkill**: 50+ dependencies vs 2 (ollama, click)
- **Abstraction overhead**: We talk directly to Ollama
- **Maintenance burden**: Frameworks evolve, APIs break
- Current ~450 lines of focused code is the right size

### Why Keep Current
- âœ… **Works** for the delegation use case
- âœ… **Minimal** dependencies
- âœ… **Focused** on read-only codebase exploration
- âœ… **Simple** to maintain and extend
- âœ… **Native** Ollama integration

---

## Roadmap

### Phase 1: Now - Improve Current Implementation

| Task | Priority | Status |
|------|----------|--------|
| Add path jailing (restrict to project root) | High | âœ… Done |
| Add model discovery (detect installed Ollama models) | High | âœ… Done |
| Add smart model selection based on task | Medium | âœ… Done |
| Add tests for allowlist/denylist behavior | Medium | âœ… Done |

### Phase 2: Next - Evaluate Smolagents + Sandboxing

**What:** Code-as-tool pattern where model writes Python instead of calling fixed tools.

**Why consider:**
- Eliminates tool maintenance entirely
- **Sandboxed execution** (better than regex allowlists)
- Model writes `import os; os.listdir('.')` instead of calling `list_directory` tool
- Smolagents requires minimum security level for code execution

**Experiment:**
1. Create `feature/smolagents` branch
2. Test with Qwen-Coder via Ollama
3. Validate code generation quality
4. If works: Replace `local_brain/tools/`
5. If doesn't: Keep current approach

#### Sandboxing Research (Required for Smolagents)

**Requirement:** Smolagents requires sandboxing for safe code execution. We need a solution that can ship with the tool (no external services).

##### Sandboxing Options Evaluated

| Solution | Type | Ship-able | Pros | Cons |
|----------|------|-----------|------|------|
| **LocalPythonExecutor** | smolagents built-in | âœ… Yes | No deps, restricted imports, no file I/O | Limited isolation, not true sandbox |
| **E2B Sandbox** | Cloud service | âŒ No | Strong isolation | Requires API key, external service |
| **Docker Sandbox** | Container | âš ï¸ Partial | Strong isolation | Requires Docker installed |
| **WebAssembly (Pyodide+Deno)** | WASM | âš ï¸ Partial | Good isolation | Complex setup, limited Python libs |
| **RestrictedPython** | AST-based | âœ… Yes | No deps, pure Python | Bypassable, limited security |
| **bubblewrap (bwrap)** | Linux syscall | âŒ No | Strong isolation | Linux-only, needs installation |

##### Recommended Approach: LocalPythonExecutor (Phase 2a)

smolagents' `LocalPythonExecutor` provides basic security without external dependencies:

```python
from smolagents.local_python_executor import LocalPythonExecutor

# Built-in restrictions:
# - No file I/O operations (open, write, etc.)
# - Restricted import list (safe modules only)
# - No subprocess/os.system calls
# - Execution timeout
```

**Trade-offs:**
- âœ… Ships with `pip install smolagents` â€” no extra setup
- âœ… Better than current regex allowlist approach
- âš ï¸ Not a true sandbox (runs in same process)
- âš ï¸ Determined attacker could potentially bypass

##### Future Enhancement: Docker Sandbox (Phase 2b)

For stronger isolation when available:

```python
from smolagents import DockerSandbox

# Strong isolation:
# - Separate container per execution
# - Network isolation
# - Resource limits
# - File system isolation
```

**Trade-offs:**
- âœ… True process isolation
- âœ… Works on macOS/Linux/Windows (with Docker)
- âš ï¸ Requires Docker to be installed
- âš ï¸ Slower execution (container startup)

##### Decision Matrix

| User Environment | Recommended Sandbox |
|------------------|---------------------|
| Docker available | Docker Sandbox (strongest) |
| Docker unavailable | LocalPythonExecutor (adequate) |
| Security-critical | Don't use smolagents, keep current tools |

#### Web Tools Consideration

**Decision:** âŒ **NOT adding web tools in Phase 1 or 2**

**Reasons:**
- **Security risk**: Data exfiltration, SSRF attacks, prompt injection from fetched content
- **Complexity**: URL validation, rate limiting, content sanitization
- **Scope creep**: Local Brain is for *local* codebase exploration
- **Dependencies**: Would add `httpx`, `beautifulsoup4`, `duckduckgo-search`

**If web tools are needed later (Phase 3+):**
- Consider **Smolagents with Docker sandbox** for safe web access
- Docker provides network isolation at container level
- See [RESEARCH_WEB_TOOLS.md](./RESEARCH_WEB_TOOLS.md) for implementation details

**Alternative for documentation lookup:**
- Claude Code already has web access
- Delegate web research to Claude, local execution to Local Brain

### Phase 3: Future - Consider MCP Bridge

**What:** Model Context Protocol (MCP) is an emerging standard for LLM tooling.

**Opportunity:** Local Brain could become the **Ollama â†” MCP bridge**:
- Receive tool schemas from MCP servers
- Translate to Ollama's tool format
- Execute via Ollama
- Return results via MCP protocol

**When to pursue:**
- MCP adoption increases
- Community needs Ollamaâ†”MCP connectivity
- High effort, high risk, high potential reward

### Future Maybe

| Task | Notes |
|------|-------|
| Retry logic for Ollama calls | Low priority, Ollama is local and usually reliable |
| Streaming support | Nice-to-have for long responses |

---

## Model Discovery & Selection

Local Brain now includes smart model management:

### Model Discovery
```python
# Automatically detects installed Ollama models
ollama.list()  # Returns all installed models with metadata
```

### Recommended Models (Tool-Calling Capable)

| Model | Size | Tool Support | Best For |
|-------|------|--------------|----------|
| `qwen3:latest` | 4.4GB | âœ… Excellent | General purpose, default |
| `qwen2.5-coder:7b` | 4.7GB | âœ… Good | Code-focused tasks |
| `llama3.2:3b` | 2.0GB | âœ… Good | Fast, lightweight |
| `mistral:7b` | 4.1GB | âœ… Good | Balanced performance |
| `deepseek-coder-v2:16b` | 8.9GB | âœ… Good | Complex code analysis |

### Auto-Selection Logic
1. Check installed models against recommended list
2. If recommended model found â†’ use it
3. If multiple found â†’ prefer by capability tier
4. If none found â†’ offer to pull recommended model

---

## Alternatives Considered

| Alternative | Verdict | Reason |
|-------------|---------|--------|
| **Aider** | âŒ Rejected | Interactive, not programmable |
| **LangChain** | âŒ Rejected | Too heavy (50+ deps), overkill |
| **LlamaIndex** | âŒ Rejected | RAG-focused, not tool-focused |
| **AutoGen** | âŒ Rejected | Multi-agent, overkill |
| **CrewAI** | âŒ Rejected | Multi-agent, overkill |
| [**Smolagents**](https://github.com/huggingface/smolagents) | ğŸ”„ Evaluate Phase 2 | Code-as-tool + LocalPythonExecutor sandbox |
| [**MCP Bridge**](https://modelcontextprotocol.io/) | ğŸ”® Future Phase 3 | If standard gains traction |
| **Web Tools** | âŒ Rejected | Security risk, out of scope |
| **E2B Sandbox** | âŒ Rejected | Requires external service/API key |
| **RestrictedPython** | âš ï¸ Considered | Bypassable, weaker than LocalPythonExecutor |

---

## Current Architecture (Approved)

```
Claude Code Skill
    â”‚
    â””â”€â”€â–º local-brain CLI
            â”‚
            â”œâ”€â”€â–º models.py (model discovery)
            â”‚       â”‚
            â”‚       â””â”€â”€â–º ollama.list() â†’ smart model selection
            â”‚
            â”œâ”€â”€â–º agent.py (tool loop)
            â”‚       â”‚
            â”‚       â””â”€â”€â–º ollama.chat(tools=[...])
            â”‚
            â””â”€â”€â–º tools/
                    â”œâ”€â”€ file_tools.py   (read_file, list_directory, file_info) [JAILED]
                    â”œâ”€â”€ git_tools.py    (git_diff, git_status, git_log, git_changed_files)
                    â””â”€â”€ shell_tools.py  (run_command with allowlist) [JAILED]
```

### Security Features
- **Path jailing**: All file operations restricted to project root
- **Command allowlist**: Only read-only shell commands permitted
- **No network access**: Prevents data exfiltration
- **Truncation limits**: Large outputs capped to prevent context overflow

### Strengths
- Direct `ollama-python` SDK usage
- ~500 lines of focused code
- 2 dependencies only
- Read-only security posture
- Smart model discovery

### Known Limitations
- Regex-based command allowlist (fragile, Phase 2 will evaluate Smolagents sandbox)
- Basic error handling
- No streaming support (yet)

---

## Research Archive

The following documents were synthesized into this decision:

| Document | Model | Stance |
|----------|-------|--------|
| `RESEARCH-claude-4.5-opus-high.md` | Claude 4.5 Opus | Deprecate or pivot |
| `RESEARCH-composer-1.md` | Composer | Keep as-is |
| `RESEARCH-gemini-3-pro.md` | Gemini 3 Pro | Use Smolagents |
| `RESEARCH-gpt-5.1-codex-max.md` | GPT-5.1 Codex Max | Redundant but valuable |

All models agreed:
- Current code is clean and well-written
- The LLM tooling space has mature alternatives
- Security implementation could be improved

The key disagreement was resolved by recognizing the **actual use case** (delegation, not standalone CLI).

---

## Conclusion

**Keep Local Brain simple and focused.** It serves a specific purpose (Claude Code â†’ Ollama delegation) that mature alternatives like Aider don't address. Improve incrementally, evaluate Smolagents when ready, and watch MCP adoption for future opportunities.

**No web tools** - Claude Code handles web research; Local Brain handles local execution.

---

*Decision approved: December 8, 2025*

